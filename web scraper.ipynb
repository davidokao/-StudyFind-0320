{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tbody><tr class=\"odd parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId1\"></a>1</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742179 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742179\" name=\"NCT04742179\" onchange=\"updateCart('NCT04742179');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742179?draw=2&amp;rank=1\" title=\"Show study NCT04742179: Fighting Climate Change: Urban Greennes, Active Mobility and Health Co-benefits.\">Fighting Climate Change: Urban Greennes, Active Mobility and Health Co-benefits.</a></td><td><ul><li>Respiratory and Allergic Symptoms</li></ul></td><td><ul><li>Other: Manteinance and care intervention on the green areas.</li></ul></td><td></td></tr><tr class=\"even parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId2\"></a>2</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742166 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742166\" name=\"NCT04742166\" onchange=\"updateCart('NCT04742166');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742166?draw=2&amp;rank=2\" title=\"Show study NCT04742166: Impact of Lateral Gastro-jejunal Anastomosis on the Rate of Gastroparesis After Cephalic Duodenopancreatectomy\">Impact of Lateral Gastro-jejunal Anastomosis on the Rate of Gastroparesis After Cephalic Duodenopancreatectomy</a></td><td><ul><li>Surgical Technique</li></ul></td><td><ul><li>Procedure: Reconstruction</li></ul></td><td><ul><li>Institut Paoli Calmettes<br/>Marseille, France</li><li>CHU de Rennes<br/>Rennes, France</li></ul></td></tr><tr class=\"odd parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId3\"></a>3</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742153 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742153\" name=\"NCT04742153\" onchange=\"updateCart('NCT04742153');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742153?draw=2&amp;rank=3\" title=\"Show study NCT04742153: A Study of MRG002 in the Treatment of Patients With HER2-low Locally Advanced or Metastatic Breast Cancer (BC)\">A Study of MRG002 in the Treatment of Patients With HER2-low Locally Advanced or Metastatic Breast Cancer (BC)</a></td><td><ul><li>Advanced or Metastatic Breast Cancer</li></ul></td><td><ul><li>Drug: MRG002</li></ul></td><td><ul><li>Fifth Medical Center of PLA General Hospital<br/>Beijing, Beijing, China</li><li>The Fourth hospital of Hebei Medical University<br/>Shijiazhuang, Hebei, China</li></ul></td></tr><tr class=\"even parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId4\"></a>4</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742140 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742140\" name=\"NCT04742140\" onchange=\"updateCart('NCT04742140');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742140?draw=2&amp;rank=4\" title=\"Show study NCT04742140: Magnesium Sulphate Injection in Treatment of Myofascial Trigger Points\">Magnesium Sulphate Injection in Treatment of Myofascial Trigger Points</a></td><td><ul><li>Trigger Point Pain, Myofascial</li></ul></td><td><ul><li>Drug: Magnesium sulfate</li><li>Drug: Saline</li></ul></td><td></td></tr><tr class=\"odd parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId5\"></a>5</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742127 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742127\" name=\"NCT04742127\" onchange=\"updateCart('NCT04742127');\" type=\"checkbox\"/></td><td><span style=\"color:#E60000;\">Active, not recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742127?draw=2&amp;rank=5\" title=\"Show study NCT04742127: Failure of a Single Surgical Debridement in Septic Arthritis of the Native Hip\">Failure of a Single Surgical Debridement in Septic Arthritis of the Native Hip</a></td><td><ul><li>Septic Arthritis of the Native Hip</li><li>Failure of Initial Debridement</li></ul></td><td><ul><li>Diagnostic Test: Single surgical debridement</li></ul></td><td><ul><li>UZ Leuven<br/>Leuven, Belgium</li></ul></td></tr><tr class=\"even parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId6\"></a>6</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742114 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742114\" name=\"NCT04742114\" onchange=\"updateCart('NCT04742114');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742114?draw=2&amp;rank=6\" title=\"Show study NCT04742114: Effect of EPAP Device on Emphysema and Lung Bullae\">Effect of EPAP Device on Emphysema and Lung Bullae</a></td><td><ul><li>Emphysema</li><li>Bullous Disease Lung</li></ul></td><td><ul><li>Device: use the face mask with Expiratory Positive Airway Pressure(EPAP).</li><li>Device: use the face mask without Expiratory Positive Airway Pressure(EPAP).</li></ul></td><td></td></tr><tr class=\"odd parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId7\"></a>7</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742101 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742101\" name=\"NCT04742101\" onchange=\"updateCart('NCT04742101');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742101?draw=2&amp;rank=7\" title=\"Show study NCT04742101: Phase I/II Trial of S65487 Plus Azacitidine in Acute Myeloid Leukemia\">Phase I/II Trial of S65487 Plus Azacitidine in Acute Myeloid Leukemia</a></td><td><ul><li>Acute Myeloid Leukemia</li></ul></td><td><ul><li>Drug: S65487 and azacitidine</li></ul></td><td></td></tr><tr class=\"even parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId8\"></a>8</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742088 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742088\" name=\"NCT04742088\" onchange=\"updateCart('NCT04742088');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742088?draw=2&amp;rank=8\" title=\"Show study NCT04742088: Assessment of the Safety and Performance of a Compression Ankle Support in the Prevention of Injuries During Sports Practice\">Assessment of the Safety and Performance of a Compression Ankle Support in the Prevention of Injuries During Sports Practice</a></td><td><ul><li>Chronic Pain</li><li>Chronic Instability of Ankle Joint</li></ul></td><td><ul><li>Device: ankleSOFT100</li></ul></td><td><ul><li>KOSS Paris 8<br/>Paris, France</li></ul></td></tr><tr class=\"odd parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId9\"></a>9</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742075 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742075\" name=\"NCT04742075\" onchange=\"updateCart('NCT04742075');\" type=\"checkbox\"/></td><td><span style=\"color:#008500;\">Not yet recruiting</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742075?draw=2&amp;rank=9\" title=\"Show study NCT04742075: Olaparib, Durvalumab and UV1 in Relapsed Ovarian Cancer\">Olaparib, Durvalumab and UV1 in Relapsed Ovarian Cancer</a></td><td><ul><li>Ovarian Cancer</li></ul></td><td><ul><li>Drug: Olaparib + durvalumab + UV1</li></ul></td><td><ul><li>Rigshospitalet<br/>København Ø, Sjaelland, Denmark</li></ul></td></tr><tr class=\"even parent\" role=\"row\"><td class=\"dt-body-right\" tabindex=\"0\"><a id=\"rowId10\"></a>10</td><td class=\"dt-body-center\"><input aria-label=\"Save Study NCT04742062 checkbox\" class=\"SavedStudyCB\" id=\"NCT04742062\" name=\"NCT04742062\" onchange=\"updateCart('NCT04742062');\" type=\"checkbox\"/></td><td><span style=\"color:#E60000;\">Completed</span><br/><span class=\"usa-label\" title=\"First Posted within the last 30 days\">New</span></td><td><a href=\"/ct2/show/NCT04742062?draw=2&amp;rank=10\" title=\"Show study NCT04742062: First in Human Clinical Trial of ApTOLL in Healthy Volunteers\">First in Human Clinical Trial of ApTOLL in Healthy Volunteers</a></td><td><ul><li>Stroke</li></ul></td><td><ul><li>Drug: ApTOLL</li><li>Other: Placebo</li></ul></td><td><ul><li>Clinical Pharmacology Department. Hospital Universitario de La Princesa<br/>Madrid, Spain</li></ul></td></tr></tbody>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://clinicaltrials.gov/ct2/results?cond=&term=&cntry=&state=&city=&dist='\n",
    "driver = webdriver.Chrome('//Users/shardulkothapalli/Desktop/SCHOOL/6.spring2021/cs3312/StudyFind-0320/chromedriver')\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "soup = BeautifulSoup(driver.page_source,'html')\n",
    "driver.quit()\n",
    "tables = soup.find_all('tbody')\n",
    "print(tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'Not yet recruitingNew', 'Fighting Climate Change: Urban Greennes, Active Mobility and Health Co-benefits.', '/ct2/show/NCT04742179?draw=2&amp;rank=1', 'Respiratory and Allergic Symptoms', 'Other: Manteinance and care intervention on the green areas.'], ['2', 'Not yet recruitingNew', 'Impact of Lateral Gastro-jejunal Anastomosis on the Rate of Gastroparesis After Cephalic Duodenopancreatectomy', '/ct2/show/NCT04742166?draw=2&amp;rank=2', 'Surgical Technique', 'Procedure: Reconstruction', 'Institut Paoli CalmettesMarseille, FranceCHU de RennesRennes, France'], ['3', 'Not yet recruitingNew', 'A Study of MRG002 in the Treatment of Patients With HER2-low Locally Advanced or Metastatic Breast Cancer (BC)', '/ct2/show/NCT04742153?draw=2&amp;rank=3', 'Advanced or Metastatic Breast Cancer', 'Drug: MRG002', 'Fifth Medical Center of PLA General HospitalBeijing, Beijing, ChinaThe Fourth hospital of Hebei Medical UniversityShijiazhuang, Hebei, China'], ['4', 'Not yet recruitingNew', 'Magnesium Sulphate Injection in Treatment of Myofascial Trigger Points', '/ct2/show/NCT04742140?draw=2&amp;rank=4', 'Trigger Point Pain, Myofascial', 'Drug: Magnesium sulfateDrug: Saline'], ['5', 'Active, not recruitingNew', 'Failure of a Single Surgical Debridement in Septic Arthritis of the Native Hip', '/ct2/show/NCT04742127?draw=2&amp;rank=5', 'Septic Arthritis of the Native HipFailure of Initial Debridement', 'Diagnostic Test: Single surgical debridement', 'UZ LeuvenLeuven, Belgium'], ['6', 'Not yet recruitingNew', 'Effect of EPAP Device on Emphysema and Lung Bullae', '/ct2/show/NCT04742114?draw=2&amp;rank=6', 'EmphysemaBullous Disease Lung', 'Device: use the face mask with Expiratory Positive Airway Pressure(EPAP).Device: use the face mask without Expiratory Positive Airway Pressure(EPAP).'], ['7', 'Not yet recruitingNew', 'Phase I/II Trial of S65487 Plus Azacitidine in Acute Myeloid Leukemia', '/ct2/show/NCT04742101?draw=2&amp;rank=7', 'Acute Myeloid Leukemia', 'Drug: S65487 and azacitidine'], ['8', 'RecruitingNew', 'Assessment of the Safety and Performance of a Compression Ankle Support in the Prevention of Injuries During Sports Practice', '/ct2/show/NCT04742088?draw=2&amp;rank=8', 'Chronic PainChronic Instability of Ankle Joint', 'Device: ankleSOFT100', 'KOSS Paris 8Paris, France'], ['9', 'Not yet recruitingNew', 'Olaparib, Durvalumab and UV1 in Relapsed Ovarian Cancer', '/ct2/show/NCT04742075?draw=2&amp;rank=9', 'Ovarian Cancer', 'Drug: Olaparib + durvalumab + UV1', 'RigshospitaletKøbenhavn Ø, Sjaelland, Denmark'], ['10', 'CompletedNew', 'First in Human Clinical Trial of ApTOLL in Healthy Volunteers', '/ct2/show/NCT04742062?draw=2&amp;rank=10', 'Stroke', 'Drug: ApTOLLOther: Placebo', 'Clinical Pharmacology Department. Hospital Universitario de La PrincesaMadrid, Spain']]\n"
     ]
    }
   ],
   "source": [
    "table = tables[1]\n",
    "big_info = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    row_list = [] \n",
    "    for cell in row.find_all([\"th\",\"td\"]):\n",
    "        temp = cell.text\n",
    "        if (temp != ''):\n",
    "            row_list.append(temp)\n",
    "        if \"href\" in str(cell):\n",
    "            href_tags = cell.find_all(href=True)\n",
    "            a = str(href_tags[0]).split(\" \")[1]        \n",
    "            row_list.append(a[6:-1])        \n",
    "    big_info.append(row_list)\n",
    "    \n",
    "print(big_info)\n",
    "\n",
    "            \n",
    "# tab_data = [[cell.text for cell in row.find_all([\"th\",\"td\"])]\n",
    "#                         for row in table.find_all(\"tr\")]\n",
    "# print(tab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIEF SUMMARY:  Prospective bi-centric randomized open-label study comparing lateral and terminolateral gastro-jejunal anastomoses in cephalic duodenopancreatectomies. \n",
      "\n",
      "DETAILLED SUMMARY:  Gastroparesis is one of the main complications occurring after cephalic duodenopancreatectomy, the incidence of which is estimated between 10 and 40% in the literature. Its occurrence leads to an alteration in post-operative quality of life (maintenance or resting of the nasogastric tube) and is the primary reason for lengthening the length of hospital stay and thus increasing the cost of treatment. In addition, it predisposes to the risk of inhalation pneumopathy, which increases the risk of post-operative death. Various technical surgical points have been suggested by retrospective studies to reduce its incidence (pyloric preservation, respect for the left gastric vein, ante-colic positioning of the Child's handle, making a Y-shaped handle) but without ever being validated in randomized prospective studies.\n",
      "Recently three retrospective studies have highlighted the interest of performing a lateral-lateral rather than a terminolateral gastro-jejunal anastomosis to reduce the rate of post-operative gastroparesis. \n",
      "\n",
      "STUDY ELIGIBILITY:  ['Ages Eligible for Study: \\xa0 ', '18 Years and older \\xa0 (Adult, Older Adult)', 'Sexes Eligible for Study: \\xa0 ', 'All', 'Accepts Healthy Volunteers: \\xa0 ', 'No'] \n",
      "\n",
      "STUDY CRITERIA:  ['\\nStudy Type  :', '\\r\\n        Interventional\\r\\n                \\xa0(Clinical Trial)\\r\\n                \\r\\n        \\r\\n      ', 'Estimated\\r\\nEnrollment  :', '166 participants', 'Allocation:', 'Randomized', 'Intervention Model:', 'Parallel Assignment', 'Masking:', ' None (Open Label)', 'Primary Purpose:', ' Other', 'Official Title:', 'Impact of Lateral Gastro-jejunal Anastomosis on the Rate of Gastroparesis After Cephalic Duodenopancreatectomy: A Prospective Randomized Study', '  Estimated Study Start Date  :', 'April 1, 2021', '  Estimated Primary Completion Date  :', 'July 1, 2023', '  Estimated Study Completion Date  :', 'July 1, 2023'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for study in big_info[1:]:\n",
    "    temp_dict = {}\n",
    "    url = 'https://clinicaltrials.gov' + study[3]\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text,'html')\n",
    "    #print(soup)\n",
    "    summ = soup.findAll(\"div\", {\"class\": \"ct-body3 tr-indent2\"})\n",
    "    temp_dict['brief summary'] = summ[0].text\n",
    "    temp_dict['detailled description'] = summ[1].text\n",
    "    summ = soup.findAll(\"div\", {\"class\": \"ct-body3 tr-indent2\"})\n",
    "\n",
    "    study_design = soup.findAll(\"table\", {\"class\": \"ct-layout_table tr-tableStyle tr-studyInfo\"})\n",
    "    tab1 = study_design[0]\n",
    "    tab1_det = []\n",
    "    for row in tab1.find_all(\"tr\"):\n",
    "        for cell in row.find_all([\"th\",\"td\"]):\n",
    "            temp = cell.text\n",
    "            if temp != '':\n",
    "                tab1_det.append(temp)\n",
    "    tab2 = study_design[1]\n",
    "    tab2_det = []\n",
    "    for row in tab2.find_all(\"tr\"):\n",
    "        for cell in row.find_all([\"th\",\"td\"]):\n",
    "            temp = cell.text\n",
    "            if temp != '':\n",
    "                tab2_det.append(temp)\n",
    "    \n",
    "    study_design = soup.findAll(\"div\", {\"class\": \"tr-indent2\"})\n",
    "    print('BRIEF SUMMARY: ', temp_dict['brief summary'], '\\n')\n",
    "    print('DETAILLED SUMMARY: ', temp_dict['detailled description'], '\\n')\n",
    "    print(\"STUDY ELIGIBILITY: \", tab2_det, '\\n')\n",
    "    print(\"STUDY CRITERIA: \", tab1_det, '\\n')\n",
    "    #print(len(study_design))\n",
    "    #for row in tab1.find_all(\"tr\")\n",
    "    #print(study_design)\n",
    "\n",
    "    break\n",
    "driver.quit()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('//Users/shardulkothapalli/Desktop/SCHOOL/6.spring2021/cs3312/StudyFind-0320/chromedriver')\n",
    "url = 'https://scholar.google.com/citations?user=mG4imMEAAAAJ&hl=en'\n",
    "url += '&view_op=list_works&sortby=pubdate'\n",
    "driver.get(url)\n",
    "soup = BeautifulSoup(driver.page_source,'html')\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,'html')\n",
    "\n",
    "\n",
    "prof = soup.findAll(\"div\", {\"id\": \"gsc_prf_i\"})\n",
    "tags = soup.findAll(\"a\", {\"class\": \"gsc_prf_inta gs_ibl\"})\n",
    "prof_info = []\n",
    "\n",
    "for row in prof[0].find_all(\"div\")[:2]:\n",
    "    prof_info.append(row.text)\n",
    "temp_tags = []\n",
    "for tag in tags:\n",
    "    temp_tags.append(tag.text)\n",
    "prof_info.append(temp_tags)\n",
    "prof_pic = driver.find_element_by_xpath('//*[@id=\"gsc_prf_pup-img\"]')\n",
    "prof_pic = prof_pic.get_attribute('src')\n",
    "\n",
    "studies = soup.findAll(\"tbody\", {\"id\": \"gsc_a_b\"})\n",
    "count = 1\n",
    "\n",
    "stoodies = []\n",
    "for row in studies[0].find_all(\"tr\", {'class': 'gsc_a_tr'}):\n",
    "    xp = '//*[@id=\"gsc_a_b\"]/tr[' + str(count) + ']/td[1]/a'\n",
    "    elem = driver.find_element_by_xpath(xp)\n",
    "    elem.click()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    try:\n",
    "        title = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_title\"]/a')\n",
    "        title = title.text\n",
    "    except:\n",
    "        title = 'no title'\n",
    "    \n",
    "    try:\n",
    "        pubdate = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[2]/div[2]')\n",
    "        pubdate = pubdate.text\n",
    "    except:\n",
    "        pubdate = 'no date'\n",
    "        \n",
    "    try:\n",
    "        pdflink = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_title_gg\"]/div/a')\n",
    "        pdflink = pdflink.get_attribute('href')\n",
    "    except:\n",
    "        pdflink = 'no link'\n",
    "        \n",
    "    try:\n",
    "        desc = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_descr\"]/div/div')\n",
    "        desc = desc.text\n",
    "    except:\n",
    "        desc = 'no description'\n",
    "    \n",
    "    study = {'title': title, 'publication date': pubdate, 'pdf link': pdflink, 'description': desc}\n",
    "    stoodies.append(study)\n",
    "    \n",
    "    elem = driver.find_element_by_xpath('//*[@id=\"gs_md_cita-d-x\"]/span[1]')\n",
    "    elem.click()\n",
    "    \n",
    "    count += 1    \n",
    "driver.quit()\n",
    "profile = {'name': prof_info[0], 'organization': prof_info[1], 'topics': prof_info[2], 'profile pic': prof_pic,\n",
    "           'studies': stoodies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Andrew Ng',\n",
       " 'organization': 'Stanford University',\n",
       " 'topics': ['Machine Learning', 'Deep Learning', 'AI'],\n",
       " 'profile pic': 'https://scholar.googleusercontent.com/citations?view_op=view_photo&user=mG4imMEAAAAJ&citpid=1',\n",
       " 'studies': [{'title': 'CheXternal: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays and External Clinical Settings',\n",
       "   'publication date': '2021/2/17',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2102.08660',\n",
       "   'description': 'Recent advances in training deep learning models have demonstrated the potential to provide accurate chest X-ray interpretation and increase access to radiology expertise. However, poor generalization due to data distribution shifts in clinical settings is a key barrier to implementation. In this study, we measured the diagnostic performance for 8 different chest X-ray models when applied to (1) smartphone photos of chest X-rays and (2) external datasets without any finetuning. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to test datasets without further tuning. We found that (1) on photos of chest X-rays, all 8 models experienced a statistically significant drop in task performance, but only 3 performed significantly worse than radiologists on average, and (2) on the external set, none of the models performed statistically significantly worse than radiologists, and five models performed statistically significantly better than radiologists. Our results demonstrate that some chest X-ray models, under clinically relevant distribution shifts, were comparable to radiologists while other models were not. Future work should investigate aspects of model training procedures and dataset collection that influence generalization in the presence of data distribution shifts.'},\n",
       "  {'title': 'Contrastive learning leveraging patient metadata improves representations for chest X-ray interpretation',\n",
       "   'publication date': '2021/2/8',\n",
       "   'pdf link': 'https://openreview.net/pdf?id=Hp5gFnDz2Bm',\n",
       "   'description': 'Self-supervised contrastive learning between pairs of multiple views of the same image has been shown to successfully leverage unlabeled data to produce meaningful visual representations for both natural and medical images. However, there has been limited work on determining how to select pairs for medical images, where availability of patient metadata can be leveraged to improve representations. In this work, we develop a method to select positive pairs coming from views of possibly different images through the use of patient metadata. We compare strategies for selecting positive pairs for chest X-ray interpretation including requiring them to be from the same patient, imaging study or laterality. We evaluate downstream task performance by fine-tuning the linear layer on 1% of the labeled dataset for pleural effusion classification. Our best performing positive pair selection strategy, which involves using images from the same patient from the same study across all lateralities, achieves a performance increase of 3.4% and 14.4% in mean AUC from both a previous contrastive method and ImageNet pretrained baseline respectively. Our controlled experiments show that the keys to improving downstream performance on disease classification are (1) using patient metadata to appropriately create positive pairs from different images with the same underlying pathologies, and (2) maximizing the number of different images used in query pairing. In addition, we explore leveraging patient metadata to select hard negative pairs for contrastive learning, but do not find improvement over baselines that do not use metadata. Our method is broadly …'},\n",
       "  {'title': 'Unseen Disease Detection for Deep Learning Interpretation of Chest X-rays',\n",
       "   'publication date': '2021/2/8',\n",
       "   'pdf link': 'https://openreview.net/pdf?id=i-zxSlqneRu',\n",
       "   'description': \"We systematically evaluate the performance of deep learning models in the presence of diseases not labeled for or present during training. First, we evaluate whether deep learning models trained on a subset of diseases (seen diseases) can detect the presence of any one of a larger set of diseases. We find that models tend to falsely classify diseases outside of the subset (unseen diseases) asno disease''. Second, we evaluate whether models trained on seen diseases can detect seen diseases when co-occurring with diseases outside the subset (unseen diseases). We find that models are still able to detect seen diseases even when co-occurring with unseen diseases. Third, we evaluate whether feature representations learned by models may be used to detect the presence of unseen diseases given a small labeled set of unseen diseases. We find that the penultimate layer provides useful features for unseen disease detection. Our results can inform the safe clinical deployment of deep learning models trained on a non-exhaustive set of disease classes.\"},\n",
       "  {'title': 'CheXseg: Combining Expert Annotations with DNN-generated Saliency Maps for X-ray Segmentation',\n",
       "   'publication date': '2021/2/4',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2102.10484',\n",
       "   'description': 'Medical image segmentation models are typically supervised by expert annotations at the pixel-level, which can be expensive to acquire. In this work, we propose a method that combines the high quality of pixel-level expert annotations with the scale of coarse DNN-generated saliency maps for training multi-label semantic segmentation models. We demonstrate the application of our semi-supervised method, which we call CheXseg, on multi-label chest x-ray interpretation. We find that CheXseg improves upon the performance (mIoU) of fully-supervised methods that use only pixel-level expert annotations by 13.4% and weakly-supervised methods that use only DNN-generated saliency maps by 91.2%. Furthermore, we implement a semi-supervised method using knowledge distillation and find that though it is outperformed by CheXseg, it exceeds the performance (mIoU) of the best fully-supervised method by 4.83%. Our best method is able to match radiologist agreement on three out of ten pathologies and reduces the overall performance gap by 71.6% as compared to weakly-supervised methods.'},\n",
       "  {'title': 'Real-time neural text-to-speech',\n",
       "   'publication date': '2021/1/28',\n",
       "   'pdf link': 'https://patentimages.storage.googleapis.com/be/ee/49/b6ffb4184351f5/US20210027762A1.pdf',\n",
       "   'description': 'Embodiments of a production-quality text-to-speech (TTS) system constructed from deep neural networks are described. System embodiments comprise five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For embodiments of the segmentation model, phoneme boundary detection was performed with deep neural networks using Connectionist Temporal Classification (CTC) loss. For embodiments of the audio synthesis model, a variant of WaveNet was created that requires fewer parameters and trains faster than the original. By using a neural network for each component, system embodiments are simpler and more flexible than traditional TTS systems, where each component requires laborious feature engineering and …'},\n",
       "  {'title': 'CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation',\n",
       "   'publication date': '2021/1/18',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2101.06871',\n",
       "   'description': 'Deep learning methods for chest X-ray interpretation typically rely on pretrained models developed for ImageNet. This paradigm assumes that better ImageNet architectures perform better on chest X-ray tasks and that ImageNet-pretrained weights provide a performance boost over random initialization. In this work, we compare the transfer performance and parameter efficiency of 16 popular convolutional architectures on a large chest X-ray dataset (CheXpert) to investigate these assumptions. First, we find no relationship between ImageNet performance and CheXpert performance for both models without pretraining and models with pretraining. Second, we find that, for models without pretraining, the choice of model family influences performance more than size within a family for medical imaging tasks. Third, we observe that ImageNet pretraining yields a statistically significant boost in performance across architectures, with a higher boost for smaller architectures. Fourth, we examine whether ImageNet architectures are unnecessarily large for CheXpert by truncating final blocks from pretrained models, and find that we can make models 3.25 x more parameter-efficient on average without a statistically significant drop in performance. Our work contributes new experimental evidence about the relation of ImageNet to chest x-ray interpretation performance.'},\n",
       "  {'title': 'Data augmentation with Mobius transformations',\n",
       "   'publication date': '2020/12/22',\n",
       "   'pdf link': 'https://iopscience.iop.org/article/10.1088/2632-2153/abd615/pdf',\n",
       "   'description': 'Data augmentation has led to substantial improvements in the performance and generalization of deep models, and remain a highly adaptable method to evolving model architectures and varying amounts of data---in particular, extremely scarce amounts of available training data. In this paper, we present a novel method of applying Mobius transformations to augment input images during training. Mobius transformations are bijective conformal maps that generalize image translation to operate over complex inversion in pixel space. As a result, Mobius transformations can operate on the sample level and preserve data labels. We show that the inclusion of Mobius transformations during training enables improved generalization over prior sample-level data augmentation techniques such as cutout and standard crop-and-flip transformations, most notably in low data regimes.'},\n",
       "  {'title': 'Systems and methods for real-time neural text-to-speech',\n",
       "   'publication date': '2020/12/22',\n",
       "   'pdf link': 'https://patentimages.storage.googleapis.com/6b/6d/34/d9b17f792d9a9b/US10872598.pdf',\n",
       "   'description': 'Embodiments of a production-quality text-to-speech (TTS) system constructed from deep neural networks are described. System embodiments comprise five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For embodiments of the segmentation model, phoneme boundary detection was performed with deep neural networks using Connectionist Temporal Classification (CTC) loss. For embodiments of the audio synthesis model, a variant of WaveNet was created that requires fewer parameters and trains faster than the original. By using a neural network for each component, system embodiments are simpler and more flexible than traditional TTS systems, where each component requires laborious feature engineering and …'},\n",
       "  {'title': 'Upscaling FLUXNET-CH4: Data-driven model performance, predictors, and regional to global methane emission estimates for freshwater wetlands',\n",
       "   'publication date': '2020/12/9',\n",
       "   'pdf link': 'no link',\n",
       "   'description': 'no description'},\n",
       "  {'title': 'Incorporating machine learning and social determinants of health indicators into prospective risk adjustment for health plan payments',\n",
       "   'publication date': '2020/12',\n",
       "   'pdf link': 'https://link.springer.com/content/pdf/10.1186/s12889-020-08735-0.pdf',\n",
       "   'description': 'Risk adjustment models are employed to prevent adverse selection, anticipate budgetary reserve needs, and offer care management services to high-risk individuals. We aimed to address two unknowns about risk adjustment: whether machine learning (ML) and inclusion of social determinants of health (SDH) indicators improve prospective risk adjustment for health plan payments.'},\n",
       "  {'title': 'AppendiXNet: Deep Learning for Diagnosis of Appendicitis from A Small Dataset of CT Exams Using Video Pretraining',\n",
       "   'publication date': '2020/12/1',\n",
       "   'pdf link': 'https://search.proquest.com/openview/af576054af9682fccccf12e1ebceb3be/1?pq-origsite=gscholar&cbl=2041939',\n",
       "   'description': 'The development of deep learning algorithms for complex tasks in digital medicine has relied on the availability of large labeled training datasets, usually containing hundreds of thousands of examples. The purpose of this study was to develop a 3D deep learning model, AppendiXNet, to detect appendicitis, one of the most common life-threatening abdominal emergencies, using a small training dataset of less than 500 training CT exams. We explored whether pretraining the model on a large collection of natural videos would improve the performance of the model over training the model from scratch. AppendiXNet was pretrained on a large collection of YouTube videos called Kinetics, consisting of approximately 500,000 video clips and annotated for one of 600 human action classes, and then fine-tuned on a small dataset of 438 CT scans annotated for appendicitis. We found that pretraining the 3D model on …'},\n",
       "  {'title': 'CheXphoto: 10,000+ Photos and Transformations of Chest X-rays for Benchmarking Deep Learning Robustness',\n",
       "   'publication date': '2020/11/23',\n",
       "   'pdf link': 'http://proceedings.mlr.press/v136/phillips20a/phillips20a.pdf',\n",
       "   'description': 'Clinical deployment of deep learning algorithms for chest x-ray interpretation requires a solution that can integrate into the vast spectrum of clinical workflows across the world. An appealing approach to scaled deployment is to leverage the ubiquity of smartphones by capturing photos of x-rays to share with clinicians using messaging services like WhatsApp. However, the application of chest x-ray algorithms to photos of chest x-rays requires reliable classification in the presence of artifacts not typically encountered in digital x-rays used to train machine learning models. We introduce CheXphoto, a dataset of smartphone photos and synthetic photographic transformations of chest x-rays sampled from the CheXpert dataset. To generate CheXphoto we (1) automatically and manually captured photos of digital x-rays under different settings, and (2) generated synthetic transformations of digital x-rays targeted to make them look like photos of digital x-rays and x-ray films. We release this dataset as a resource for testing and improving the robustness of deep learning algorithms for automated chest x-ray interpretation on smartphone photos of chest x-rays.'},\n",
       "  {'title': 'Ngboost: Natural gradient boosting for probabilistic prediction',\n",
       "   'publication date': '2020/11/21',\n",
       "   'pdf link': 'http://proceedings.mlr.press/v119/duan20a/duan20a.pdf',\n",
       "   'description': 'We present Natural Gradient Boosting (NGBoost), an algorithm for generic probabilistic prediction via gradient boosting. Typical regression models return a point estimate, conditional on covariates, but probabilistic regression models output a full probability distribution over the outcome space, conditional on the covariates. This allows for predictive uncertainty estimation-crucial in applications like healthcare and weather forecasting. NGBoost generalizes gradient boosting to probabilistic regression by treating the parameters of the conditional distribution as targets for a multiparameter boosting algorithm. Furthermore, we show how the Natural Gradient is required to correct the training dynamics of our multiparameter boosting approach. NGBoost can be used with any base learner, any family of distributions with continuous parameters, and any scoring rule. NGBoost matches or exceeds the performance of existing methods for probabilistic prediction while offering additional benefits in flexibility, scalability, and usability. An open-source implementation is available at github. com/stanfordmlgroup/ngboost.'},\n",
       "  {'title': 'OGNet: Towards a Global Oil and Gas Infrastructure Database using Deep Learning on Remotely Sensed Imagery',\n",
       "   'publication date': '2020/11/14',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2011.07227',\n",
       "   'description': 'At least a quarter of the warming that the Earth is experiencing today is due to anthropogenic methane emissions. There are multiple satellites in orbit and planned for launch in the next few years which can detect and quantify these emissions; however, to attribute methane emissions to their sources on the ground, a comprehensive database of the locations and characteristics of emission sources worldwide is essential. In this work, we develop deep learning algorithms that leverage freely available high-resolution aerial imagery to automatically detect oil and gas infrastructure, one of the largest contributors to global methane emissions. We use the best algorithm, which we call OGNet, together with expert review to identify the locations of oil refineries and petroleum terminals in the US We show that OGNet detects many facilities which are not present in four standard public datasets of oil and gas infrastructure. All detected facilities are associated with characteristics known to contribute to methane emissions, including the infrastructure type and the number of storage tanks. The data curated and produced in this study is freely available at this http URL.'},\n",
       "  {'title': 'CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays',\n",
       "   'publication date': '2020/11/12',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2011.06129',\n",
       "   'description': 'The use of smartphones to take photographs of chest x-rays represents an appealing solution for scaled deployment of deep learning models for chest x-ray interpretation. However, the performance of chest x-ray algorithms on photos of chest x-rays has not been thoroughly investigated. In this study, we measured the diagnostic performance for 8 different chest x-ray models when applied to photos of chest x-rays. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to smartphone photos of x-rays in the CheXphoto dataset without further tuning. We found that several models had a drop in performance when applied to photos of chest x-rays, but even with this drop, some models still performed comparably to radiologists. Further investigation could be directed towards understanding how different model training procedures may affect model generalization to photos of chest x-rays.'},\n",
       "  {'title': 'ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep Learning on Satellite Imagery',\n",
       "   'publication date': '2020/11/11',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2011.05479',\n",
       "   'description': 'Characterizing the processes leading to deforestation is critical to the development and implementation of targeted forest conservation and management policies. In this work, we develop a deep learning model called ForestNet to classify the drivers of primary forest loss in Indonesia, a country with one of the highest deforestation rates in the world. Using satellite imagery, ForestNet identifies the direct drivers of deforestation in forest loss patches of any size. We curate a dataset of Landsat 8 satellite images of known forest loss events paired with driver annotations from expert interpreters. We use the dataset to train and validate the models and demonstrate that ForestNet substantially outperforms other standard driver classification approaches. In order to support future research on automated approaches to deforestation driver classification, the dataset curated in this study is publicly available at this https URL.'},\n",
       "  {'title': 'Deep learning assistance for the histopathologic diagnosis of Helicobacter pylori',\n",
       "   'publication date': '2020/11/1',\n",
       "   'pdf link': 'https://www.sciencedirect.com/science/article/pii/S2666521220300041',\n",
       "   'description': 'no description'},\n",
       "  {'title': 'GloFlow: Global Image Alignment for Creation of Whole Slide Images for Pathology from Video',\n",
       "   'publication date': '2020/10/28',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2010.15269',\n",
       "   'description': 'The application of deep learning to pathology assumes the existence of digital whole slide images of pathology slides. However, slide digitization is bottlenecked by the high cost of precise motor stages in slide scanners that are needed for position information used for slide stitching. We propose GloFlow, a two-stage method for creating a whole slide image using optical flow-based image registration with global alignment using a computationally tractable graph-pruning approach. In the first stage, we train an optical flow predictor to predict pairwise translations between successive video frames to approximate a stitch. In the second stage, this approximate stitch is used to create a neighborhood graph to produce a corrected stitch. On a simulated dataset of video scans of WSIs, we find that our method outperforms known approaches to slide-stitching, and stitches WSIs resembling those produced by slide scanners.'},\n",
       "  {'title': 'MoCo pretraining improves representation and transferability of chest X-ray models',\n",
       "   'publication date': '2020/10/11',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2010.05352',\n",
       "   'description': 'Self-supervised approaches such as Momentum Contrast (MoCo) can leverage unlabeled data to produce pretrained models for subsequent fine-tuning on labeled data. While MoCo has demonstrated promising results on natural image classification tasks, its application to medical imaging tasks like chest X-ray interpretation has been limited. Chest X-ray interpretation is fundamentally different from natural image classification in ways that may limit the applicability of self-supervised approaches. In this work, we investigate whether MoCo-pretraining leads to better representations or initializations for chest X-ray interpretation. We conduct MoCo-pretraining on CheXpert, a large labeled dataset of X-rays, followed by supervised fine-tuning experiments on the pleural effusion task. Using 0.1% of labeled training data, we find that a linear model trained on MoCo-pretrained representations outperforms one trained on representations without MoCo-pretraining by an AUC of 0.096 (95% CI 0.061, 0.130), indicating that MoCo-pretrained representations are of higher quality. Furthermore, a model fine-tuned end-to-end with MoCo-pretraining outperforms its non-MoCo-pretrained counterpart by an AUC of 0.037 (95% CI 0.015, 0.062) with the 0.1% label fraction. These AUC improvements are observed for all label fractions for both the linear model and an end-to-end fine-tuned model with the greater improvements for smaller label fractions. Finally, we observe similar results on a small, target chest X-ray dataset (Shenzhen dataset for tuberculosis) with MoCo-pretraining done on the source dataset (CheXpert), which suggests that pretraining on unlabeled X …'},\n",
       "  {'title': 'Short-Term Solar Irradiance Forecasting Using Calibrated Probabilistic Models',\n",
       "   'publication date': '2020/10/9',\n",
       "   'pdf link': 'https://arxiv.org/pdf/2010.04715',\n",
       "   'description': 'Advancing probabilistic solar forecasting methods is essential to supporting the integration of solar energy into the electricity grid. In this work, we develop a variety of state-of-the-art probabilistic models for forecasting solar irradiance. We investigate the use of post-hoc calibration techniques for ensuring well-calibrated probabilistic predictions. We train and evaluate the models using public data from seven stations in the SURFRAD network, and demonstrate that the best model, NGBoost, achieves higher performance at an intra-hourly resolution than the best benchmark solar irradiance forecasting model across all stations. Further, we show that NGBoost with CRUDE post-hoc calibration achieves comparable performance to a numerical weather prediction model on hourly-resolution forecasting.'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import heapq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24).\n",
      "\n",
      "Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17).\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "for stoo in profile['studies']:\n",
    "    formatted_desc = re.sub('[^a-zA-Z]', ' ', stoo['description'] )\n",
    "    formatted_desc = re.sub(r'\\s+', ' ', formatted_desc)\n",
    "    formatted_desc = formatted_desc.lower()\n",
    "    sentence_list = nltk.sent_tokenize(stoo['description'])\n",
    "    \n",
    "    word_frequencies = {}\n",
    "    for word in nltk.word_tokenize(formatted_desc):\n",
    "        if word not in stopwords:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "                \n",
    "                \n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)            \n",
    "    \n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_list:\n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "    \n",
    "    summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    print(stoo['description'])\n",
    "    print('')\n",
    "    print(summary)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
